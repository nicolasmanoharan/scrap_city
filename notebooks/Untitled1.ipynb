{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f40071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/rs890ggx6mv9__ry8_4g0zk00000gp/T/ipykernel_9995/40325784.py:110: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath(xpath).click()\n",
      "/var/folders/4z/rs890ggx6mv9__ry8_4g0zk00000gp/T/ipykernel_9995/40325784.py:116: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath(\"/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span/span[2]/span[1]/button\").click()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clique sur le nombre d'avis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/rs890ggx6mv9__ry8_4g0zk00000gp/T/ipykernel_9995/40325784.py:129: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  total_number_of_reviews =driver.find_element_by_xpath(xpath_nb_avis).text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le log a été enregistré avec succès.\n",
      "aucun commentaire détecter\n"
     ]
    },
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: Malformed URL: URL constructor: Motortech Toulon is not a valid URL.\nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:191:5\nInvalidArgumentError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:382:5\nGeckoDriver.prototype.navigateTo@chrome://remote/content/marionette/driver.sys.mjs:825:11\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 258>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    256\u001b[0m         get_list_review_google(url, entreprise, name, nb_avis)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m#entreprise = \"Leroy Merlin\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m#url = 'https://www.google.fr/maps/place/Leroy+Merlin+Collégien/@48.8350548,2.660387,17z/data=!4m8!3m7!1s0x47fa21b36c8d581f:0x4b608c92ba1bf7f!8m2!3d48.8350548!4d2.6625757!9m1!1b1!16s%2Fg%2F1pxwgmh18'\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m#    \"https://www.google.com/maps/place/Motortech+Performance+Toulon/@43.1449545,6.022858,17z/data=!4m8!3m7!1s0x12c9178cc5482ac3:0xfffd9d6d633c5dfe!8m2!3d43.1449545!4d6.0250467!9m1!1b1!16s%2Fg%2F1tmmhk1h?entry=ttu\",\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m#    nb_avis_disponible=0)\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    254\u001b[0m nb_avis \u001b[38;5;241m=\u001b[39m nb_avis\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m#delta = row['delta']\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m \u001b[43mget_list_review_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentreprise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_avis\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mget_list_review_google\u001b[0;34m(url, entreprise, name, nb_avis)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_list_review_google\u001b[39m(url, entreprise,name, nb_avis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 207\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[43mget_google_review\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentreprise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_avis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tmp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m :\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mget_google_review\u001b[0;34m(url, entreprise, name, nb_avis)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_google_review\u001b[39m(url, entreprise, name, nb_avis):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Import the webdriver\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mFirefox(service\u001b[38;5;241m=\u001b[39mFirefoxService(GeckoDriverManager()\u001b[38;5;241m.\u001b[39minstall()))\n\u001b[0;32m--> 105\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# privacy pop-up\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     xpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/html/body/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/div[1]/form[2]/div/div/button/span\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/scrap_city/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:442\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/scrap_city/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:430\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    428\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[1;32m    432\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/scrap_city/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:247\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    245\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mInvalidArgumentException\u001b[0m: Message: Malformed URL: URL constructor: Motortech Toulon is not a valid URL.\nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:191:5\nInvalidArgumentError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:382:5\nGeckoDriver.prototype.navigateTo@chrome://remote/content/marionette/driver.sys.mjs:825:11\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "# Fonction pour enregistrer le log dans le fichier CSV\n",
    "def rec_log(entreprise, name, url, nb_avis_disponible, delta=None):\n",
    "    # Obtenir la date et l'heure actuelles\n",
    "    date_execution = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Créer un DataFrame avec les nouvelles données du log\n",
    "    log_data = {\n",
    "        'entreprise': [entreprise],\n",
    "        'name': [name],\n",
    "        'url': [url],\n",
    "        'nb_avis': [nb_avis_disponible],\n",
    "        'delta': [delta],\n",
    "        'date': [date_execution]\n",
    "    }\n",
    "    new_df = pd.DataFrame(log_data)\n",
    "\n",
    "    # Vérifier si le fichier CSV existe\n",
    "    fichier_existe = os.path.isfile('log.csv')\n",
    "\n",
    "    if fichier_existe:\n",
    "        # Lire le fichier CSV existant\n",
    "        existing_df = pd.read_csv('log.csv')\n",
    "\n",
    "        # Concaténer les données existantes avec les nouvelles données\n",
    "        updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "\n",
    "        # Écrire le DataFrame mis à jour dans le fichier CSV\n",
    "        updated_df.to_csv('log.csv', index=False)\n",
    "    else:\n",
    "        # Écrire le DataFrame initial dans un nouveau fichier CSV\n",
    "        new_df.to_csv('log.csv', index=False)\n",
    "\n",
    "    # Afficher un message de confirmation\n",
    "    print('Le log a été enregistré avec succès.')\n",
    "\n",
    "def transform_date(A):\n",
    "    #A[\"Review Rate\"] = [i.split(\"\\xa0\")[0] for i in A[\"Review Rate\"]]\n",
    "    A[\"Review Time\"] = [i.strip(\"il y a \") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"une\", \"1\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"un\", \"1\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"\\xa0\", \" \") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"ans\", \"an\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"an\", \"ans\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"jours\", \"jour\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"jour\", \"jours\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"semaine\", \"semaines\")\n",
    "                        for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"semaines\", \"semaine\")\n",
    "                        for i in A[\"Review Time\"]]\n",
    "    A[\"Review date collected\"] = pd.to_datetime(A[\"Review date collected\"])\n",
    "    return A\n",
    "\n",
    "def estimated_date(google_date,collected_date) :\n",
    "    units = google_date.split(\" \")[1]\n",
    "    nunits = google_date.split(\" \")[0]\n",
    "    if (units == \"minute\") | (units == \"minutes\") :\n",
    "        temp = collected_date - relativedelta(minutes=int(nunits))\n",
    "    if (units == \"heures\") | (units == \"heure\") :\n",
    "        temp = collected_date - relativedelta(hours=int(nunits))\n",
    "    if (units == \"jours\") | (units == \"jours\") :\n",
    "        temp = collected_date - relativedelta(days=int(nunits))\n",
    "    if (units == \"semaines\") | (units == \"semaine\") :\n",
    "        temp = collected_date - relativedelta(weeks=int(nunits))\n",
    "    if units == \"mois\" :\n",
    "        temp = collected_date - relativedelta(months=int(nunits))\n",
    "    if units == \"ans\" :\n",
    "        temp = collected_date - relativedelta(years=int(nunits))\n",
    "    return temp\n",
    "\n",
    "def get_review_summary(result_set):\n",
    "    rev_dict = {'Review Rate': [],\n",
    "        'Review Time': [],\n",
    "        'Review Text' : [],\n",
    "        'Review date collected':[]}\n",
    "\n",
    "    for result in result_set:\n",
    "        review_rate = len(result.findAll('img', attrs={'class':'hCCjke vzX5Ic','src':'//maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_14.png'}))\n",
    "        review_time = result.find('span',class_='rsqaWe').text\n",
    "\n",
    "        try :\n",
    "            review_text = result.find('span', class_='wiI7pd').text\n",
    "        except :\n",
    "            review_text = \"\"\n",
    "        rev_dict['Review Rate'].append(review_rate)\n",
    "        rev_dict['Review Time'].append(review_time)\n",
    "        rev_dict['Review Text'].append(review_text)\n",
    "        rev_dict['Review date collected'].append(datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return(pd.DataFrame(rev_dict))\n",
    "\n",
    "def get_google_review(url, entreprise, name, nb_avis):\n",
    "    # Import the webdriver\n",
    "    driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install()))\n",
    "    driver.get(url)\n",
    "\n",
    "    # privacy pop-up\n",
    "    xpath = \"/html/body/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/div[1]/form[2]/div/div/button/span\"\n",
    "    try :\n",
    "        driver.find_element_by_xpath(xpath).click()\n",
    "    except :\n",
    "        print(\"xpath not necessary\")\n",
    "\n",
    "\n",
    "    try :\n",
    "        driver.find_element_by_xpath(\"/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span/span[2]/span[1]/button\").click()\n",
    "    except :\n",
    "        print(\"Clique sur le nombre d'avis\")\n",
    "    #### expand the review\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    class_ = \"ODSEW-KoToPc-ShBeI gXqMYb-hSRGPd\"\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "\n",
    "    xpath_nb_avis = \"/html/body/div[2]/div[3]/div[8]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]/div/div[2]/div[3]\"\n",
    "    #total_number_of_reviews = soup.find(\"div\", class_=\"gm2-caption\").text\n",
    "    total_number_of_reviews =driver.find_element_by_xpath(xpath_nb_avis).text\n",
    "\n",
    "\n",
    "\n",
    "    ## Catch nombre d'avis\n",
    "    total_number_of_reviews = float(\n",
    "        total_number_of_reviews.split(\" \")[-2].replace(\"\\u202f\", \"\"))\n",
    "    if nb_avis is not None :\n",
    "        rec_log(entreprise, name, url, total_number_of_reviews,\n",
    "            total_number_of_reviews - float(nb_avis))\n",
    "    else :\n",
    "        rec_log(entreprise, name, url, float(total_number_of_reviews))\n",
    "\n",
    "    # Check if there are new comment\n",
    "    if nb_avis == total_number_of_reviews:\n",
    "        print(\"aucun commentaire détecter\")\n",
    "        driver.close()\n",
    "        return # sys.exit()\n",
    "\n",
    "    time.sleep(1)\n",
    "    try :\n",
    "        xpatrier = \"/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[8]/div[2]/button/span/span\"\n",
    "        driver.find_element_by_xpath(xpatrier).click()\n",
    "    except :\n",
    "        print(\"echec ouverture Trier\")\n",
    "\n",
    "    time.sleep(2)\n",
    "    xpatrecent = \"/html/body/div[3]/div[3]/div[1]/div[2]\"\n",
    "    driver.find_element_by_xpath(xpatrecent).click()\n",
    "\n",
    "    ## Catch cellule of reviews\n",
    "\n",
    "    books_html = soup.findAll('div', class_ =\"jftiEf fontBodyMedium\")\n",
    "    len(books_html)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Find scroll layout\n",
    "    old_scroll = '//*[@id=\"pane\"]/div/div[1]/div/div/div[2]'\n",
    "    old_scroll = \"/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]\"\n",
    "    scroll = \"/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]\"\n",
    "    scrollable_div = driver.find_element_by_xpath(scroll)\n",
    "    #Scroll as many times as necessary to load all reviews\n",
    "\n",
    "\n",
    "    if nb_avis is not None :\n",
    "        total_number_of_reviews = total_number_of_reviews - float(nb_avis)\n",
    "\n",
    "    if total_number_of_reviews >= 10 :\n",
    "        for i in (range(0, (round(total_number_of_reviews / 10 - 1)))):\n",
    "            driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight',\n",
    "                    scrollable_div)\n",
    "            time.sleep(2)\n",
    "    try :\n",
    "        liste_plus =driver.find_elements_by_xpath('//button[normalize-space()=\"Plus\"]')\n",
    "    except :\n",
    "        print(\"stop\")\n",
    "    for i in liste_plus :\n",
    "        try :\n",
    "            i.click()\n",
    "        except :\n",
    "            print(\"tant pis\")\n",
    "\n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "\n",
    "    #reviews = response.find_all('div',\n",
    "    #                            class_='MyEned')\n",
    "\n",
    "    reviews = response.find_all(\"div\", class_=\"jftiEf fontBodyMedium\")\n",
    "    reviews = reviews[:int(total_number_of_reviews)]\n",
    "\n",
    "\n",
    "    driver.close()\n",
    "    return reviews\n",
    "\n",
    "def get_list_review_google(url, entreprise,name, nb_avis=None):\n",
    "    tmp = get_google_review(url, entreprise, name, nb_avis)\n",
    "    if tmp is None :\n",
    "        return\n",
    "    tmp = get_review_summary(tmp)\n",
    "    tmp = transform_date(tmp)\n",
    "    tmp[\"review estimated date\"] = [estimated_date(i, j) for i, j in zip(\n",
    "        tmp[\"Review Time\"], tmp[\"Review date collected\"])]\n",
    "    tmp = tmp.replace('\\|', ',', regex=True)\n",
    "    name = entreprise + \"_\" + name  # Remplacez par le nom souhaité pour le fichier CSV\n",
    "\n",
    "    # Code pour générer le dataframe tmp\n",
    "\n",
    "    # Vérifier si le fichier existe\n",
    "    if os.path.isfile(name + '.csv'):\n",
    "        # Le fichier existe, ajouter les lignes au fichier CSV existant\n",
    "        tmp.to_csv(name + '.csv', sep='|', encoding='utf-8', index=False, mode='a', header= False)\n",
    "    else:\n",
    "        # Le fichier n'existe pas, créer un nouveau fichier CSV avec les lignes\n",
    "        tmp.to_csv(name + '.csv', sep='|', encoding='utf-8', index=False)\n",
    "    return tmp\n",
    "\n",
    "def test():\n",
    "    # Chemin vers le fichier CSV\n",
    "    chemin_fichier = 'log.csv'\n",
    "\n",
    "    # Charger le fichier CSV avec pandas\n",
    "    data_frame = pd.read_csv(chemin_fichier)\n",
    "\n",
    "    # Convertir la colonne \"date\" en type datetime\n",
    "    data_frame['date'] = pd.to_datetime(data_frame['date'])\n",
    "\n",
    "    # Trier le dataframe par ordre décroissant de la colonne de date\n",
    "    data_frame = data_frame.sort_values('date', ascending=False)\n",
    "    # Regrouper les lignes par les colonnes qui doivent être identiques\n",
    "    groupes = data_frame.groupby(['entreprise', 'name', 'url'])\n",
    "\n",
    "    # Sélectionner la ligne la plus récente dans chaque groupe\n",
    "    lignes_recentes = groupes.apply(\n",
    "        lambda x: x[x['date'] == x['date'].max()]['nb_avis'])\n",
    "\n",
    "    # Obtenir les lignes correspondantes du dataframe original\n",
    "    #lignes_selectionnees = data_frame.loc[lignes_recentes]\n",
    "    # Parcourir les lignes sélectionnées\n",
    "    for index, nb_avis in lignes_recentes.iteritems():\n",
    "        entreprise = index[0]\n",
    "        name = index[1]\n",
    "        url = index[2]\n",
    "        nb_avis = nb_avis\n",
    "        #delta = row['delta']\n",
    "        get_list_review_google(url, entreprise, name, nb_avis)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #entreprise = \"Leroy Merlin\"\n",
    "    #url = 'https://www.google.fr/maps/place/Leroy+Merlin+Collégien/@48.8350548,2.660387,17z/data=!4m8!3m7!1s0x47fa21b36c8d581f:0x4b608c92ba1bf7f!8m2!3d48.8350548!4d2.6625757!9m1!1b1!16s%2Fg%2F1pxwgmh18'\n",
    "    #name = 'Collegien'\n",
    "    #get_list_review_google(url, entreprise,name)\n",
    "    #rec_log(\n",
    "    #    entreprise=\"Motortech\",\n",
    "    #    name=\"Motortech Toulon\",\n",
    "    #    url=\n",
    "    #    \"https://www.google.com/maps/place/Motortech+Performance+Toulon/@43.1449545,6.022858,17z/data=!4m8!3m7!1s0x12c9178cc5482ac3:0xfffd9d6d633c5dfe!8m2!3d43.1449545!4d6.0250467!9m1!1b1!16s%2Fg%2F1tmmhk1h?entry=ttu\",\n",
    "    #    nb_avis_disponible=0)\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d0a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entreprise=\"Motortech\"\n",
    "name=\"Motortech Toulon\"\n",
    "url=\"https://www.google.com/maps/place/Motortech+Performance+Toulon/@43.1449545,6.022858,17z/data=!4m8!3m7!1s0x12c9178cc5482ac3:0xfffd9d6d633c5dfe!8m2!3d43.1449545!4d6.0250467!9m1!1b1!16s%2Fg%2F1tmmhk1h?entry=ttu\"\n",
    "nb_avis_disponible=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb9f5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/rs890ggx6mv9__ry8_4g0zk00000gp/T/ipykernel_9995/40325784.py:110: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath(xpath).click()\n",
      "/var/folders/4z/rs890ggx6mv9__ry8_4g0zk00000gp/T/ipykernel_9995/40325784.py:116: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath(\"/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span/span[2]/span[1]/button\").click()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clique sur le nombre d'avis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/rs890ggx6mv9__ry8_4g0zk00000gp/T/ipykernel_9995/40325784.py:129: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  total_number_of_reviews =driver.find_element_by_xpath(xpath_nb_avis).text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le log a été enregistré avec succès.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/rs890ggx6mv9__ry8_4g0zk00000gp/T/ipykernel_9995/40325784.py:151: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath(xpatrier).click()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echec ouverture Trier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/rs890ggx6mv9__ry8_4g0zk00000gp/T/ipykernel_9995/40325784.py:157: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath(xpatrecent).click()\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: Unable to locate element: /html/body/div[3]/div[3]/div[1]/div[2]\nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:191:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:509:5\ndom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_google_review\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mentreprise\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnb_avis_disponible\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mget_google_review\u001b[0;34m(url, entreprise, name, nb_avis)\u001b[0m\n\u001b[1;32m    155\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    156\u001b[0m xpatrecent \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/html/body/div[3]/div[3]/div[1]/div[2]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 157\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element_by_xpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxpatrecent\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclick()\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m## Catch cellule of reviews\u001b[39;00m\n\u001b[1;32m    161\u001b[0m books_html \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfindAll(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_ \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjftiEf fontBodyMedium\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/scrap_city/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:526\u001b[0m, in \u001b[0;36mWebDriver.find_element_by_xpath\u001b[0;34m(self, xpath)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03mFinds an element by xpath.\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m        element = driver.find_element_by_xpath('//div/td[1]')\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    521\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfind_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    524\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    525\u001b[0m )\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/scrap_city/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:1251\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[1;32m   1249\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/scrap_city/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:430\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    428\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[1;32m    432\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/scrap_city/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:247\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    245\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: Unable to locate element: /html/body/div[3]/div[3]/div[1]/div[2]\nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:191:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:509:5\ndom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n"
     ]
    }
   ],
   "source": [
    "get_google_review(url,entreprise,name,nb_avis_disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a190f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
