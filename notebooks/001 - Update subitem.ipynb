{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79109fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 10:59:27,774 - INFO - ====== WebDriver manager ======\n",
      "2024-12-24 10:59:27,979 - INFO - Get LATEST geckodriver version for 133.0 firefox\n",
      "2024-12-24 10:59:28,268 - INFO - Get LATEST geckodriver version for 133.0 firefox\n",
      "2024-12-24 10:59:28,416 - INFO - Driver [/Users/magellan/.wdm/drivers/geckodriver/mac64/v0.35.0/geckodriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import csv\n",
    "import logging  # <-- Ajout du module logging\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "import re\n",
    "\n",
    "# Import pour By\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Configuration de base du logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Pour afficher les logs de niveau INFO et supérieur\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "sele = FirefoxService(GeckoDriverManager().install())\n",
    "\n",
    "\n",
    "\n",
    "def parse_pbk6be_divs(divs):\n",
    "    \"\"\"\n",
    "    Prend en entrée une liste de <div class=\"PBK6be\"> (BeautifulSoup)\n",
    "    et retourne un dictionnaire contenant, si présents :\n",
    "      - Service : \"À emporter\"\n",
    "      - Prix par personne : \"10–20 €\"\n",
    "      - Cuisine : \"5\"\n",
    "      - Service_score : \"4\"\n",
    "      - Ambiance : \"4\"\n",
    "      - Type de repas : \"Déjeuner\"\n",
    "      - Plats recommandés : \"Salade À Composer\"\n",
    "      - Options pour les végétariens : \"Beaucoup d’options\"\n",
    "    \"\"\"\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for div in divs:\n",
    "        # Récupère tout le texte \"brut\" du <div> pour d’éventuels tests simples\n",
    "        full_text = div.get_text(strip=True)\n",
    "\n",
    "        # 1) CAS « SCORE » (ex. \"<b>Service</b> : 4\", \"<b>Cuisine</b> : 5\", \"<b>Ambiance</b> : 4\")\n",
    "        # --------------------------------------------------------------------------\n",
    "        # On cherche un <b> suivi de \" : X\"\n",
    "        b_elem = div.find(\"b\")\n",
    "        if b_elem:\n",
    "            # Exemple de texte possible dans b_elem.parent : \"Cuisine : 5\"\n",
    "            # -> On fait un test via regex\n",
    "            match = re.search(r\"(Cuisine|Service|Ambiance)\\s*:\\s*(\\d+)\", b_elem.parent.get_text(strip=True))\n",
    "            if match:\n",
    "                label = match.group(1)       # \"Cuisine\", \"Service\", ou \"Ambiance\"\n",
    "                score = match.group(2)      # ex. \"4\" ou \"5\"\n",
    "\n",
    "                # Pour distinguer le \"Service\" normal (ex. \"À emporter\") du \"Service\" score (ex. \"4\"),\n",
    "                # on stocke la valeur dans \"Service_score\" si c’est le cas.\n",
    "                if label == \"Service\":\n",
    "                    data[\"Service_score\"] = score\n",
    "                else:\n",
    "                    data[label] = score\n",
    "\n",
    "                continue  # On passe au div suivant, pas besoin d’analyser plus\n",
    "\n",
    "        # 2) CAS « LABEL : VALEUR » (ex. \"Service\" => \"À emporter\", \"Prix par personne\" => \"10–20 €\", etc.)\n",
    "        # --------------------------------------------------------------------------\n",
    "        # On identifie un \"span\" avec style=\"font-weight: bold;\" ou un simple get_text()\n",
    "        #    <span style=\"font-weight: bold;\">Service</span> puis la valeur est dans l'autre <span> ...\n",
    "        bold_span = div.find(\"span\", style=re.compile(r\"font-weight:\\s*bold\"))\n",
    "        if bold_span:\n",
    "            # Exemple : \"Service\", \"Prix par personne\", \"Type de repas\", \"Plats recommandés\", \"Options pour les végétariens\"\n",
    "            label_text = bold_span.get_text(strip=True)\n",
    "\n",
    "            # La valeur est souvent dans le <div> ou <span> en-dessous\n",
    "            # On va prendre tout le texte du div après avoir retiré le label lui-même\n",
    "            # Exemple de full_text : \"ServiceÀ emporter\"\n",
    "            # On retire \"Service\" pour isoler \"À emporter\"\n",
    "            # (en s'assurant de bien gérer les espaces)\n",
    "            remainder = full_text.replace(label_text, \"\", 1).strip()\n",
    "\n",
    "            # S’il y a des sauts de ligne, on peut nettoyer\n",
    "            remainder = remainder.replace(\"\\n\", \"\")\n",
    "            remainder = re.sub(r'\\s+', ' ', remainder)\n",
    "            # On enregistre\n",
    "            data[label_text] = remainder\n",
    "\n",
    "            continue  # On passe au div suivant\n",
    "\n",
    "        # 3) CAS PARTICULIER : si aucun <b> ni style font-weight: bold, \n",
    "        #    vous pouvez ajouter d’autres règles si nécessaire.\n",
    "        # --------------------------------------------------------------------------\n",
    "        # Par exemple, \"Prix par personne\" pourrait parfois se trouver autrement.\n",
    "        # Ou un label \"Type de repas\" écrit différemment.\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Fonction pour enregistrer le log dans le fichier CSV\n",
    "def rec_log(entreprise, name, url, nb_avis_disponible, delta=None):\n",
    "    logging.info(f\"Entrée dans rec_log() avec entreprise={entreprise}, name={name}, url={url}, nb_avis_disponible={nb_avis_disponible}, delta={delta}\")\n",
    "    # Obtenir la date et l'heure actuelles\n",
    "    date_execution = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Créer un DataFrame avec les nouvelles données du log\n",
    "    log_data = {\n",
    "        'entreprise': [entreprise],\n",
    "        'name': [name],\n",
    "        'url': [url],\n",
    "        'nb_avis': [nb_avis_disponible],\n",
    "        'delta': [delta],\n",
    "        'date': [date_execution]\n",
    "    }\n",
    "    new_df = pd.DataFrame(log_data)\n",
    "\n",
    "    # Vérifier si le fichier CSV existe\n",
    "    fichier_existe = os.path.isfile('log.csv')\n",
    "    logging.info(f\"Fichier log.csv existe ? {fichier_existe}\")\n",
    "\n",
    "    if fichier_existe:\n",
    "        # Lire le fichier CSV existant\n",
    "        existing_df = pd.read_csv('log.csv')\n",
    "        # Concaténer les données existantes avec les nouvelles données\n",
    "        updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "        # Écrire le DataFrame mis à jour dans le fichier CSV\n",
    "        updated_df.to_csv('log.csv', index=False)\n",
    "    else:\n",
    "        # Écrire le DataFrame initial dans un nouveau fichier CSV\n",
    "        new_df.to_csv('log.csv', index=False)\n",
    "\n",
    "    # Afficher un message de confirmation\n",
    "    print('Le log a été enregistré avec succès.')\n",
    "    logging.info(\"Le log a bien été enregistré dans log.csv\")\n",
    "\n",
    "def transform_date(A):\n",
    "    logging.info(\"Entrée dans transform_date()\")\n",
    "    #A[\"Review Rate\"] = [i.split(\"\\xa0\")[0] for i in A[\"Review Rate\"]]\n",
    "    A[\"Review Time\"] = [i.strip(\"il y a \") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"une\", \"1\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"un\", \"1\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"\\xa0\", \" \") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"ans\", \"an\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"an\", \"ans\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"jours\", \"jour\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"jour\", \"jours\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"semaine\", \"semaines\")\n",
    "                        for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"semaines\", \"semaine\")\n",
    "                        for i in A[\"Review Time\"]]\n",
    "    A[\"Review date collected\"] = pd.to_datetime(A[\"Review date collected\"])\n",
    "    logging.info(\"transform_date() a terminé la transformation des champs Review Time.\")\n",
    "    return A\n",
    "\n",
    "def estimated_date(google_date, collected_date):\n",
    "    logging.info(f\"Entrée dans estimated_date() avec google_date='{google_date}', collected_date='{collected_date}'\")\n",
    "    units = google_date.split(\" \")[1]\n",
    "    nunits = google_date.split(\" \")[0]\n",
    "    temp = collected_date\n",
    "    try:\n",
    "        if (units == \"minute\") | (units == \"minutes\"):\n",
    "            temp = collected_date - relativedelta(minutes=int(nunits))\n",
    "        if (units == \"heures\") | (units == \"heure\"):\n",
    "            temp = collected_date - relativedelta(hours=int(nunits))\n",
    "        if (units == \"jours\") | (units == \"jours\"):\n",
    "            temp = collected_date - relativedelta(days=int(nunits))\n",
    "        if (units == \"semaines\") | (units == \"semaine\"):\n",
    "            temp = collected_date - relativedelta(weeks=int(nunits))\n",
    "        if units == \"mois\":\n",
    "            temp = collected_date - relativedelta(months=int(nunits))\n",
    "        if units == \"ans\":\n",
    "            temp = collected_date - relativedelta(years=int(nunits))\n",
    "    except ValueError as e:\n",
    "        logging.warning(f\"Problème lors de la conversion en int(nunits): {e}\")\n",
    "    logging.info(f\"estimated_date() retourne la date estimée : {temp}\")\n",
    "    return temp\n",
    "\n",
    "def get_review_summary(result_set):\n",
    "    logging.info(f\"Entrée dans get_review_summary() pour {len(result_set)} reviews trouvées.\")\n",
    "    rev_dict = {'Review Rate': [],\n",
    "        'Review Service': [],\n",
    "        'Review Ambiance': [],\n",
    "        'Review Service_score': [],\n",
    "        'Review Cuisine' : [],\n",
    "        'Review Type de repas' : [],\n",
    "        'Review Plats recommandés' : [],\n",
    "        'Review Time': [],\n",
    "        'Review Text' : [],\n",
    "        'Review date collected':[]}\n",
    "\n",
    "    for idx, result in enumerate(result_set, start=1):\n",
    "        try:\n",
    "            review_rate = result.find('span',class_='kvMYJc')['aria-label']\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erreur lors de l'extraction du 'Review Rate' : {e}\")\n",
    "            review_rate = \"N/A\"\n",
    "        review_time = result.find('span',class_='rsqaWe').text\n",
    "        try:\n",
    "            review_text = result.find('span', class_='wiI7pd').text\n",
    "        except:\n",
    "            review_text = \"\"\n",
    "        try :\n",
    "            review_subitem_raw = result.find_all(\"div\", class_=\"PBK6be\")\n",
    "            tmp = parse_pbk6be_divs(review_subitem_raw)\n",
    "            try : \n",
    "                review_service = tmp[\"Service\"]\n",
    "            except :\n",
    "                logging.error(f\"Erreur lors de l'extraction review_service\")\n",
    "                review_service = \"\"\n",
    "            try : \n",
    "                review_cuisine = tmp[\"Cuisine\"]\n",
    "            except :\n",
    "                logging.error(f\"Erreur lors de l'extraction review_cuisine\")\n",
    "                review_cuisine = \"\"\n",
    "            try : \n",
    "                review_service_score = tmp[\"Service_score\"]\n",
    "            except :\n",
    "                logging.error(f\"Erreur lors de l'extraction review_service_score\")\n",
    "                review_service_score = \"\"\n",
    "            try :\n",
    "                review_ambiance = tmp[\"Ambiance\"]\n",
    "            except :\n",
    "                logging.error(f\"Erreur lors de l'extraction review_ambiance\")\n",
    "                review_ambiance = \"\"\n",
    "            try : \n",
    "                review_type = tmp[\"Type de repas\"]\n",
    "            except :\n",
    "                logging.error(f\"Erreur lors de l'extraction review_type\")\n",
    "                review_type=\"\"\n",
    "            try :\n",
    "                review_recommandation = tmp['Review Plats recommandés']\n",
    "            except :\n",
    "                logging.error(f\"Erreur lors de l'extraction review_recommandation\")\n",
    "                review_recommandation = \"\"\n",
    "        except : \n",
    "            logging.error(f\"Erreur lors de l'extraction des sub-tems\")\n",
    "            review_service = \"\"\n",
    "            review_cuisine = \"\"\n",
    "            review_service_score = \"\"\n",
    "            review_ambiance = \"\"\n",
    "            review_type = \"\"\n",
    "            review_recommandation = \"\"\n",
    "        tmp = parse_pbk6be_divs(review_subitem_raw)\n",
    "        \n",
    "        rev_dict['Review Plats recommandés'].append(review_recommandation)\n",
    "        rev_dict['Review Type de repas'].append(review_type)\n",
    "        rev_dict[\"Review Service\"].append(review_service)\n",
    "        rev_dict[\"Review Ambiance\"].append(review_ambiance)\n",
    "        rev_dict[\"Review Service_score\"].append(review_service_score)\n",
    "        rev_dict[\"Review Cuisine\"].append(review_cuisine)\n",
    "        rev_dict['Review Rate'].append(review_rate)\n",
    "        rev_dict['Review Time'].append(review_time)\n",
    "        rev_dict['Review Text'].append(review_text)\n",
    "        rev_dict['Review date collected'].append(datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    logging.info(\"get_review_summary() a fini de constituer le dataframe.\")\n",
    "    return(pd.DataFrame(rev_dict))\n",
    "\n",
    "def get_google_review(url, entreprise, name, nb_avis):\n",
    "    logging.info(f\"Entrée dans get_google_review() pour {entreprise} - {name} - nb_avis={nb_avis}\")\n",
    "    # Import the webdriver\n",
    "    driver = webdriver.Firefox(service=sele)\n",
    "    driver.get(url)\n",
    "\n",
    "    # privacy pop-up\n",
    "    xpath = \"/html/body/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/div[1]/form[2]/div/div/button/span\"\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, xpath).click()\n",
    "        logging.info(\"Pop-up de confidentialité cliquée avec succès.\")\n",
    "    except:\n",
    "        logging.warning(\"Pop-up de confidentialité introuvable ou déjà fermée.\")\n",
    "\n",
    " #   try:\n",
    " #       driver.find_element(By.XPATH,\n",
    " #           \"/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span/span[2]/span[1]/button\"\n",
    " #       ).click()\n",
    " #       logging.info(\"Clic sur le nombre d'avis effectué.\")\n",
    " #   except:\n",
    " #       logging.warning(\"Impossible de cliquer sur le nombre d'avis.\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "\n",
    "    xpath_nb_avis = \"/html/body/div[2]/div[3]/div[8]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]/div/div[2]/div[3]\"\n",
    "    try:\n",
    "        total_number_of_reviews_text = driver.find_element(By.XPATH, xpath_nb_avis).text\n",
    "        total_number_of_reviews = float(total_number_of_reviews_text.split(\" \")[-2].replace(\"\\u202f\", \"\"))\n",
    "        logging.info(f\"Nombre total d'avis détectés : {total_number_of_reviews}\")\n",
    "    except Exception as e:\n",
    "        total_number_of_reviews = 0\n",
    "        logging.error(f\"Erreur lors de la récupération du nombre d'avis : {e}\")\n",
    "\n",
    "    # Catch nombre d'avis\n",
    "    if nb_avis is not None:\n",
    "        diff = total_number_of_reviews - float(nb_avis)\n",
    "        rec_log(entreprise, name, url, total_number_of_reviews, diff)\n",
    "    else:\n",
    "        rec_log(entreprise, name, url, float(total_number_of_reviews))\n",
    "\n",
    "    # Check if there are new comment\n",
    "    if nb_avis == total_number_of_reviews:\n",
    "        print(\"aucun commentaire détecter\")\n",
    "        logging.info(\"Aucun nouveau commentaire à extraire, on quitte.\")\n",
    "        driver.close()\n",
    "        return # sys.exit()\n",
    "\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        xpatrier = \"/html/body/div[2]/div[3]/div[8]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[8]/div[2]/button/span\"\n",
    "        driver.find_element(By.XPATH, xpatrier).click()\n",
    "        logging.info(\"Menu 'Trier' ouvert avec succès.\")\n",
    "    except:\n",
    "        logging.warning(\"Échec de l'ouverture du menu 'Trier'.\")\n",
    "\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        xpatrecent = \"/html/body/div[2]/div[3]/div[3]/div[1]/div[2]\"\n",
    "        driver.find_element(By.XPATH, xpatrecent).click()\n",
    "        logging.info(\"Triage par avis les plus récents cliqué avec succès.\")\n",
    "    except:\n",
    "        logging.warning(\"Échec du bouton 'avis les plus récents'.\")\n",
    "\n",
    "    books_html = soup.findAll('div', class_ =\"jftiEf fontBodyMedium\")\n",
    "    logging.info(f\"Nombre de reviews trouvées avant scrolling : {len(books_html)}\")\n",
    "\n",
    "    #Find scroll layout\n",
    "    #old_scroll = '//*[@id=\"pane\"]/div/div[1]/div/div/div[2]'\n",
    "    #old_scroll = \"/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]\"\n",
    "    scroll = \"/html/body/div[2]/div[3]/div[8]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]\"\n",
    "\n",
    "    try:\n",
    "        scrollable_div = driver.find_element(By.XPATH, scroll)\n",
    "    except:\n",
    "        scrollable_div = None\n",
    "        logging.error(\"Impossible de trouver l'élément scrollable.\")\n",
    "\n",
    "    if nb_avis is not None:\n",
    "        total_number_of_reviews = total_number_of_reviews - float(nb_avis)\n",
    "\n",
    "    if scrollable_div and total_number_of_reviews >= 10:\n",
    "        for i in range(0, (round(total_number_of_reviews / 10 - 1))):\n",
    "            driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "            time.sleep(2)\n",
    "        logging.info(\"Scrolling terminé pour charger d'autres avis.\")\n",
    "    else:\n",
    "        logging.info(\"Pas de scrolling nécessaire ou scrollable_div introuvable.\")\n",
    "\n",
    "    try:\n",
    "        liste_plus = driver.find_elements(By.XPATH, '//button[normalize-space()=\"Plus\"]')\n",
    "        for idx, plus_button in enumerate(liste_plus, start=1):\n",
    "            try:\n",
    "                plus_button.click()\n",
    "            except:\n",
    "                logging.warning(f\"Impossible de cliquer sur le bouton 'Plus' n°{idx}.\")\n",
    "    except:\n",
    "        logging.warning(\"Aucun bouton 'Plus' trouvé.\")\n",
    "\n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    reviews = response.find_all(\"div\", class_=\"jftiEf fontBodyMedium\")\n",
    "    reviews = reviews[:int(total_number_of_reviews)]\n",
    "    logging.info(f\"Nombre de reviews réellement renvoyées : {len(reviews)}\")\n",
    "\n",
    "    driver.close()\n",
    "    logging.info(\"Fermeture du navigateur dans get_google_review().\")\n",
    "    return reviews\n",
    "\n",
    "def get_list_review_google(url, entreprise, name, nb_avis=None):\n",
    "    logging.info(f\"Entrée dans get_list_review_google() pour url={url}, entreprise={entreprise}, name={name}, nb_avis={nb_avis}\")\n",
    "    tmp = get_google_review(url, entreprise, name, nb_avis)\n",
    "    if tmp is None:\n",
    "        logging.info(\"Aucune review récupérée, fin de la fonction.\")\n",
    "        return\n",
    "    tmp = get_review_summary(tmp)\n",
    "    tmp = transform_date(tmp)\n",
    "    tmp[\"review estimated date\"] = [estimated_date(i, j) for i, j in zip(\n",
    "        tmp[\"Review Time\"], tmp[\"Review date collected\"])]\n",
    "\n",
    "    tmp = tmp.replace('\\|', ',', regex=True)\n",
    "    filename = entreprise + \"_\" + name  # Nom pour le fichier CSV\n",
    "\n",
    "    # Vérifier si le fichier existe\n",
    "    if os.path.isfile(filename + '.csv'):\n",
    "        tmp.to_csv(filename + '.csv', sep='|', encoding='utf-8', index=False, mode='a', header=False)\n",
    "        logging.info(f\"{len(tmp)} reviews ajoutées au fichier existant : {filename}.csv\")\n",
    "    else:\n",
    "        tmp.to_csv(filename + '.csv', sep='|', encoding='utf-8', index=False)\n",
    "        logging.info(f\"Fichier créé : {filename}.csv avec {len(tmp)} reviews.\")\n",
    "    return tmp\n",
    "\n",
    "def test():\n",
    "    logging.info(\"Début de la fonction test().\")\n",
    "    # Chemin vers le fichier CSV\n",
    "    chemin_fichier = 'log.csv'\n",
    "\n",
    "    # Charger le fichier CSV avec pandas\n",
    "    data_frame = pd.read_csv(chemin_fichier)\n",
    "    logging.info(f\"log.csv chargé avec {len(data_frame)} lignes.\")\n",
    "\n",
    "    # Convertir la colonne \"date\" en type datetime\n",
    "    data_frame['date'] = pd.to_datetime(data_frame['date'])\n",
    "\n",
    "    # Trier le dataframe par ordre décroissant de la colonne de date\n",
    "    data_frame = data_frame.sort_values('date', ascending=False)\n",
    "\n",
    "    # Regrouper les lignes par les colonnes qui doivent être identiques\n",
    "    groupes = data_frame.groupby(['entreprise', 'name', 'url'])\n",
    "    logging.info(\"Groupby effectué sur (entreprise, name, url).\")\n",
    "\n",
    "    # Sélectionner la ligne la plus récente dans chaque groupe\n",
    "    lignes_recentes = groupes.apply(\n",
    "        lambda x: x[x['date'] == x['date'].max()]['nb_avis'])\n",
    "\n",
    "    # Parcourir les lignes sélectionnées\n",
    "    for index, nb_avis in lignes_recentes.iteritems():\n",
    "        entreprise = index[0]\n",
    "        name = index[1]\n",
    "        url = index[2]\n",
    "        logging.info(f\"test() - groupe : entreprise={entreprise}, name={name}, url={url}, nb_avis={nb_avis}\")\n",
    "        get_list_review_google(url, entreprise, name, nb_avis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d5bea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 10:59:29,217 - INFO - Entrée dans get_list_review_google() pour url=https://www.google.fr/maps/place/Compose+Bois-Colombes+-+Cantine+sur+mesure/@48.9071788,2.2594644,17z/data=!4m8!3m7!1s0x47e665321f7e8b8b:0xe7e1d262385f4e67!8m2!3d48.9071753!4d2.2620393!9m1!1b1!16s%2Fg%2F11tg7p7k1t?entry=ttu&g_ep=EgoyMDI0MTIxMS4wIKXMDSoASAFQAw%3D%3D, entreprise=Compose, name=Compose Bois-Colombes, nb_avis=145\n",
      "2024-12-24 10:59:29,219 - INFO - Entrée dans get_google_review() pour Compose - Compose Bois-Colombes - nb_avis=145\n",
      "2024-12-24 10:59:32,138 - INFO - Pop-up de confidentialité cliquée avec succès.\n",
      "2024-12-24 10:59:34,208 - INFO - Nombre total d'avis détectés : 151.0\n",
      "2024-12-24 10:59:34,208 - INFO - Entrée dans rec_log() avec entreprise=Compose, name=Compose Bois-Colombes, url=https://www.google.fr/maps/place/Compose+Bois-Colombes+-+Cantine+sur+mesure/@48.9071788,2.2594644,17z/data=!4m8!3m7!1s0x47e665321f7e8b8b:0xe7e1d262385f4e67!8m2!3d48.9071753!4d2.2620393!9m1!1b1!16s%2Fg%2F11tg7p7k1t?entry=ttu&g_ep=EgoyMDI0MTIxMS4wIKXMDSoASAFQAw%3D%3D, nb_avis_disponible=151.0, delta=6.0\n",
      "2024-12-24 10:59:34,210 - INFO - Fichier log.csv existe ? True\n",
      "2024-12-24 10:59:34,213 - INFO - Le log a bien été enregistré dans log.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le log a été enregistré avec succès.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 10:59:35,458 - INFO - Menu 'Trier' ouvert avec succès.\n",
      "2024-12-24 10:59:37,720 - INFO - Triage par avis les plus récents cliqué avec succès.\n",
      "2024-12-24 10:59:37,723 - INFO - Nombre de reviews trouvées avant scrolling : 8\n",
      "2024-12-24 10:59:37,725 - INFO - Pas de scrolling nécessaire ou scrollable_div introuvable.\n",
      "2024-12-24 10:59:39,983 - INFO - Nombre de reviews réellement renvoyées : 6\n",
      "2024-12-24 10:59:40,376 - INFO - Fermeture du navigateur dans get_google_review().\n",
      "2024-12-24 10:59:40,377 - INFO - Entrée dans get_review_summary() pour 6 reviews trouvées.\n",
      "2024-12-24 10:59:40,378 - ERROR - Erreur lors de l'extraction review_recommandation\n",
      "2024-12-24 10:59:40,379 - ERROR - Erreur lors de l'extraction review_service\n",
      "2024-12-24 10:59:40,379 - ERROR - Erreur lors de l'extraction review_cuisine\n",
      "2024-12-24 10:59:40,379 - ERROR - Erreur lors de l'extraction review_type\n",
      "2024-12-24 10:59:40,379 - ERROR - Erreur lors de l'extraction review_recommandation\n",
      "2024-12-24 10:59:40,380 - ERROR - Erreur lors de l'extraction review_service\n",
      "2024-12-24 10:59:40,381 - ERROR - Erreur lors de l'extraction review_type\n",
      "2024-12-24 10:59:40,381 - ERROR - Erreur lors de l'extraction review_recommandation\n",
      "2024-12-24 10:59:40,382 - ERROR - Erreur lors de l'extraction review_service\n",
      "2024-12-24 10:59:40,382 - ERROR - Erreur lors de l'extraction review_recommandation\n",
      "2024-12-24 10:59:40,383 - ERROR - Erreur lors de l'extraction review_service\n",
      "2024-12-24 10:59:40,383 - ERROR - Erreur lors de l'extraction review_type\n",
      "2024-12-24 10:59:40,383 - ERROR - Erreur lors de l'extraction review_recommandation\n",
      "2024-12-24 10:59:40,384 - ERROR - Erreur lors de l'extraction review_service\n",
      "2024-12-24 10:59:40,384 - ERROR - Erreur lors de l'extraction review_type\n",
      "2024-12-24 10:59:40,384 - ERROR - Erreur lors de l'extraction review_recommandation\n",
      "2024-12-24 10:59:40,385 - INFO - get_review_summary() a fini de constituer le dataframe.\n",
      "2024-12-24 10:59:40,385 - INFO - Entrée dans transform_date()\n",
      "2024-12-24 10:59:40,387 - INFO - transform_date() a terminé la transformation des champs Review Time.\n",
      "2024-12-24 10:59:40,387 - INFO - Entrée dans estimated_date() avec google_date='1 semaine', collected_date='2024-12-24 10:59:40'\n",
      "2024-12-24 10:59:40,387 - INFO - estimated_date() retourne la date estimée : 2024-12-17 10:59:40\n",
      "2024-12-24 10:59:40,387 - INFO - Entrée dans estimated_date() avec google_date='1 semaine', collected_date='2024-12-24 10:59:40'\n",
      "2024-12-24 10:59:40,388 - INFO - estimated_date() retourne la date estimée : 2024-12-17 10:59:40\n",
      "2024-12-24 10:59:40,388 - INFO - Entrée dans estimated_date() avec google_date='1 semaine', collected_date='2024-12-24 10:59:40'\n",
      "2024-12-24 10:59:40,388 - INFO - estimated_date() retourne la date estimée : 2024-12-17 10:59:40\n",
      "2024-12-24 10:59:40,388 - INFO - Entrée dans estimated_date() avec google_date='1 semaine', collected_date='2024-12-24 10:59:40'\n",
      "2024-12-24 10:59:40,388 - INFO - estimated_date() retourne la date estimée : 2024-12-17 10:59:40\n",
      "2024-12-24 10:59:40,389 - INFO - Entrée dans estimated_date() avec google_date='1 semaine', collected_date='2024-12-24 10:59:40'\n",
      "2024-12-24 10:59:40,389 - INFO - estimated_date() retourne la date estimée : 2024-12-17 10:59:40\n",
      "2024-12-24 10:59:40,389 - INFO - Entrée dans estimated_date() avec google_date='1 semaine', collected_date='2024-12-24 10:59:40'\n",
      "2024-12-24 10:59:40,389 - INFO - estimated_date() retourne la date estimée : 2024-12-17 10:59:40\n",
      "2024-12-24 10:59:40,391 - INFO - 6 reviews ajoutées au fichier existant : Compose_Compose Bois-Colombes.csv\n"
     ]
    }
   ],
   "source": [
    "raw_data = get_list_review_google(\"https://www.google.fr/maps/place/Compose+Bois-Colombes+-+Cantine+sur+mesure/@48.9071788,2.2594644,17z/data=!4m8!3m7!1s0x47e665321f7e8b8b:0xe7e1d262385f4e67!8m2!3d48.9071753!4d2.2620393!9m1!1b1!16s%2Fg%2F11tg7p7k1t?entry=ttu&g_ep=EgoyMDI0MTIxMS4wIKXMDSoASAFQAw%3D%3D\",\"Compose\",\"Compose Bois-Colombes\", nb_avis=145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5503224e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Rate</th>\n",
       "      <th>Review Service</th>\n",
       "      <th>Review Ambiance</th>\n",
       "      <th>Review Service_score</th>\n",
       "      <th>Review Cuisine</th>\n",
       "      <th>Review Type de repas</th>\n",
       "      <th>Review Plats recommandés</th>\n",
       "      <th>Review Time</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review date collected</th>\n",
       "      <th>review estimated date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 étoiles</td>\n",
       "      <td>À emporter</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Déjeuner</td>\n",
       "      <td></td>\n",
       "      <td>1 semaine</td>\n",
       "      <td>Super service le personnel est adorable !</td>\n",
       "      <td>2024-12-24 10:59:40</td>\n",
       "      <td>2024-12-17 10:59:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 étoiles</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1 semaine</td>\n",
       "      <td></td>\n",
       "      <td>2024-12-24 10:59:40</td>\n",
       "      <td>2024-12-17 10:59:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 étoiles</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1 semaine</td>\n",
       "      <td></td>\n",
       "      <td>2024-12-24 10:59:40</td>\n",
       "      <td>2024-12-17 10:59:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 étoiles</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Déjeuner</td>\n",
       "      <td></td>\n",
       "      <td>1 semaine</td>\n",
       "      <td></td>\n",
       "      <td>2024-12-24 10:59:40</td>\n",
       "      <td>2024-12-17 10:59:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 étoiles</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1 semaine</td>\n",
       "      <td></td>\n",
       "      <td>2024-12-24 10:59:40</td>\n",
       "      <td>2024-12-17 10:59:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5 étoiles</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1 semaine</td>\n",
       "      <td>Salade délicieuse, accueil au top !\\nJ’y vais ...</td>\n",
       "      <td>2024-12-24 10:59:40</td>\n",
       "      <td>2024-12-17 10:59:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Review Rate Review Service Review Ambiance Review Service_score  \\\n",
       "0   5 étoiles     À emporter               5                    5   \n",
       "1   4 étoiles                              4                    5   \n",
       "2   4 étoiles                              3                    5   \n",
       "3   4 étoiles                              5                    4   \n",
       "4   5 étoiles                              5                    5   \n",
       "5   5 étoiles                              5                    5   \n",
       "\n",
       "  Review Cuisine Review Type de repas Review Plats recommandés Review Time  \\\n",
       "0              5             Déjeuner                            1 semaine   \n",
       "1                                                                1 semaine   \n",
       "2              4                                                 1 semaine   \n",
       "3              4             Déjeuner                            1 semaine   \n",
       "4              5                                                 1 semaine   \n",
       "5              5                                                 1 semaine   \n",
       "\n",
       "                                         Review Text Review date collected  \\\n",
       "0          Super service le personnel est adorable !   2024-12-24 10:59:40   \n",
       "1                                                      2024-12-24 10:59:40   \n",
       "2                                                      2024-12-24 10:59:40   \n",
       "3                                                      2024-12-24 10:59:40   \n",
       "4                                                      2024-12-24 10:59:40   \n",
       "5  Salade délicieuse, accueil au top !\\nJ’y vais ...   2024-12-24 10:59:40   \n",
       "\n",
       "  review estimated date  \n",
       "0   2024-12-17 10:59:40  \n",
       "1   2024-12-17 10:59:40  \n",
       "2   2024-12-17 10:59:40  \n",
       "3   2024-12-17 10:59:40  \n",
       "4   2024-12-17 10:59:40  \n",
       "5   2024-12-17 10:59:40  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[2].find_all(\"div\", class_=\"PBK6be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rev_dict = {'Review Rate': [],\n",
    "        'Review Cuisine': [],        \n",
    "        'Review Time': [],\n",
    "        'Review Text' : [],\n",
    "        'Review date collected':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for idx, result in enumerate(raw_data, start=1):\n",
    "        try:\n",
    "            review_rate = result.find('span',class_='kvMYJc')['aria-label']\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erreur lors de l'extraction du 'Review Rate' : {e}\")\n",
    "            review_rate = \"N/A\"\n",
    "        review_time = result.find('span',class_='rsqaWe').text\n",
    "        try:\n",
    "            review_text = result.find('span', class_='wiI7pd').text\n",
    "        except:\n",
    "            review_text = \"\"\n",
    "        try :\n",
    "            review_cuisine =  result.find('span', class_='RfD05c').find('b').find_next_sibling(text=True)\n",
    "# Nettoie et affiche le résultat\n",
    "        except : \n",
    "            review_cuisine = \"\"\n",
    "\n",
    "        rev_dict['Review Rate'].append(review_rate)\n",
    "        rev_dict[\"Review Cuisine\"].append(review_cuisine)\n",
    "        rev_dict['Review Time'].append(review_time)\n",
    "        rev_dict['Review Text'].append(review_text)\n",
    "        rev_dict['Review date collected'].append(datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    logging.info(\"get_review_summary() a fini de constituer le dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f97164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = raw_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2effac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.find('span', class_='wiI7pd').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d6e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6698bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    " element = tt.find_all(\"div\", class_=\"PBK6be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5ec20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86643021",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = parse_pbk6be_divs(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0bf3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"Service\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    " cuisine = element.split(':')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4848bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in element:\n",
    "    # Récupère tout le texte du <div>\n",
    "    text = div.get_text(strip=True)\n",
    "    # On cherche un motif du type : « (Cuisine|Service|Ambiance) : <chiffre> »\n",
    "    match = re.search(r'(Cuisine|Service|Ambiance)\\s*:\\s*(\\d+)', text)\n",
    "    if match:\n",
    "        label, value = match.groups()\n",
    "        print(f\"{label} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e7c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier que l'élément a été trouvé\n",
    "if element:\n",
    "    # Trouver le texte suivant (après \"Service :\")\n",
    "    parent = element.parent\n",
    "    if parent:\n",
    "        # Extraire la valeur après \":\"\n",
    "        service_value = parent.text.split(\":\")[-1].strip()\n",
    "        print(\"Service:\", service_value)\n",
    "    else:\n",
    "        print(\"Parent introuvable.\")\n",
    "else:\n",
    "    print(\"Balise contenant 'Service' introuvable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53003dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.find('span',class_='RfD05c').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a745e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
